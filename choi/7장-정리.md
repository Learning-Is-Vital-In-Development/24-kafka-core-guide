# 7장 - 신뢰성 있는 데이터 전달

<aside>
✨ 신뢰성 있는 시스템을 구축하는 데는 트레이드 오프가 있는 법이고, 카프카는 이러한 트레이드오프들을 조절할 수 있도록 개발자나 운영자가 설정한 매개변수를 조절함으로써 어느 정도의 신뢰성이 필요한지를 결정할 수 있도록 개발되었다.

</aside>

### 카프카가 보장하는 것

- 파티션 안의 메시지들 간의 순서(같은 프로듀서가 동일한 파티션에 썼을 경우)
- 클라이언트가 쓴 메시지는 모든 인-싱크 레플리카의 파티션에 쓰여진 뒤에야 커밋된 것으로 간주된다.
- 커밋된 메시지들은 최소 1개의 작동 가능한 레플리카가 남아 있는 한 유실되지 않는다.
- 컨슈머는 커밋된 메시지만 읽을 수 있다.

## 복제

- 파티션은 하나의 디스크에 저장된다.
- 팔로워 레플리카가 인-싱크 상태인 것으로 간주되는 조건
    - 주키퍼와의 활성 세션이 있다(최근 6초 사이에 주키퍼로 하트비트를 전송)
    - 최근 10초 사이 리더로부터 메시지를 읽어 왔다.
    - 최근 10초 사이에 리더로부터 읽어온 메시지들이 가장 최근 메시지이다.
- 동기화가 풀린 레플리카는 주키퍼와 다시 연결되어 리더 파티션에 쓰여진 가장 최근 메시지까지 따라잡으면 다시 인-싱크 래플리카가 된다.

## 브로커 설정

- 신뢰성 관련 브로커의 설정 매개변수들은 브로커 단위로 적용하거나 토픽 단위로 적용할 수 있다.

### 복제 팩터

- 복제 팩터가 3(default)라는 뜻은 각 브로커가 3대의 서로 다른 브로커에 3개 복제된다는 것을 의미한다.
- 복제 펙터의 개수는 가용성과 하드웨어 사용량 사이의 트레이드오프이다.
- 복제 팩터 설정값의 핵심 고려사항
    - **가용성**: 레플리카가 하나뿐인 파티션은 정기적으로 브로커가 재시작하기만 해도 작동 불능에 빠진다.
    - **지속성**: 각 레플리카는 파티션 안의 모든 데이터의 복사본이기에 레플리카가 하나 뿐이면 디스크 사용 불능시 모든 데이터는 유실된다.
    - **처리량**: 레플리카가 추가될 때마다 브로커간 트래픽 역시 늘어난다.
    - **종단 지연**: 특정 브로커가 느려지면 해당 브로커를 사용하는 모든 클라이언트 역시 복제 팩터에 무관하게 느려질 것이다.
    - **비용**: 더 많은 레플리카를 가질수록 저장소와 네트워크에 들어가는 비용 역시 증가한다.
- broker.rack 브로커 설정 매개변수에 랙 이름을 잡아주면, 카프카는 파티션의 레플리카들이 서로 다른 랙에 분산되어 저장되도록 함으로써 가용성을 높인다.

### 언클린 리더 선출

- unclean.leader.election.enable 설정으로 브로커 단위에서만 가능하다. (기본값 false)
- 만약 이 값을 true로 바꾸면 다음과 같은 상황에 out-of-sync 레플리카가 리더가 될 수 있다.
    - 한 파티션 안에 모든 in-sync 레플리카가 중단(오프라인) 상태인 상황에서 한 파티션이 온라인으로 바뀌면 이 파티션은 out-of-sync 레플리카이지만, 리더가 될 수 있다.
- 이 설정을 허용하면 데이터 유실과 일관성 깨짐이 위험성이 있지만, 가용성을 늘릴 수 있다.

### 최소 in-sync 레플리카

- min.insync.replicas 설정은 토픽과 브로커 모두 적용 가능하다.
- 만약 토픽에 레플리카가 3개 있고 min.insync.replicas를 2로 잡아 줬다면 프로듀서들은 3개의 레플리카 중 최소 2개가 in-sync 상태인 파티션에만 쓸 수 있다.
- 해당 설정이 있는 이유는 단일 레플리카 상태일 때 해당 브로커가 영구적으로 장애가 발생할 경우 데이터 복구가 불가능할 수 있기 때문이다.

### 레플리카를 인-싱크 상태로 유지하기

- 주키퍼와의 연결이 끊어지거나 리더 업데이트 내역을 따라가는데 실패해서 복제 랙이 발생하면 out-of-sync 레플리카가 발생하고, 이는 전반적인 신뢰성을 낮춘다.
- zookeeper.session.timeout.ms를 통해 카프카 브로커가 주키퍼로 하트비트 전송을 멈출 수 있는 최대 시간을 정의할 수 있다.
- replica.lag.time.max.ms 설정값보다 더 오랫동안 리더로부터 데이터를 읽어오지 못하거나, 리더에 쓰여진 최신 메시지를 따라잡지 못하는 경우 동기화가 풀린 out-of-sync 상태가 된다.

### 디스크에 저장하기

- 카프카는 세그먼트를 교체할 때(기본값: 1GB)와 재시작 직전에만 메시지를 디스크로 플라시하며, 그 외의 경우에는 리눅스의 페이지 캐시 기능에 의존한다.
- flush.messages 설정: 디스크에 저장되지 않은 최대 메시지 수
- flush.ms: 얼마나 자주 디스크에 메시지를 저장하는지 조절

## 신뢰성 있는 시스템에서 프로듀서 사용하기

- 브로커에 가장 높은 신뢰성 설정을 하더라도 프로듀서가 신뢰성 요구 조건에 맞는 올바른 asks 설정을 사용하고, 설정과 코드 모두에서 에러를 올바르게 처리하지 않으면 신뢰성 있는 시스템을 만들 수 없다.
- 예를 들면 acks=all로 설정하지 않거나, 브로커가 에러를 응답했을 때 재시도를 하지 않는 경우가 있을 수 있다.
- 프로듀서가 메시지 재전송하는 가장 좋은 방법은 재시도 수를 기본 설정값으로 두고, 메시지 전송을 포기할 때까지 대기할 수 있는 시간을 지정하는 [delevery.timeout.ms](http://delevery.timeout.ms) 설정값을 최대로 잡아두는 것이다.

## 신뢰성 있는 시스템에서 컨슈머 사용하기

- 특정 카프카 컨슈머가 작동을 정지하면, 또 다른 컨슈머 입장에서는 어디서부터 작업을 재개해야 할지 알아야 할 필요가 있다.
- 컨수머가 읽어온 오프셋을 커밋해야 하는 이유는 읽고 있는 각 파티션에 대해 어디까지 읽었는지를 저장해 둬야 해당 컨슈머나 다른 컨슈머가 재시작한 뒤에도 어디서부터 작업을 계속해야 할지 알 수 있기 때문이다.

### 신뢰성 있는 처리를 위해 중요한 컨슈머 설정

- auto.offset.reset: 커밋된 오프셋이 없을 때나 컨슈머가 브로커에 없는 오프셋을 요청할 때 컨슈머가 어떻게 해야 할지를 결정한다.
    - earliest: 유효한 오프셋이 없는 한 컨슈머는 파티션의 맨 앞부터 읽는다.(중복 처리될 수 있지만 데이터 유실 최소화)
    - latest: 파티션의 끝에서부터 읽는다.(중복 처리 최소화하지만, 컨슈머가 일부 메시지는 누락)
- enable.auto.commit: 일정한 시간에 맞춰 컨슈머가 알아서 오프셋을 커밋할지, 코드에서 직접 오프셋을 커밋할지 결정
    - 컨슈머가 읽지 않은 오프셋을 실수로 커밋하지 않도록 보장하지만, 메시지 중복 처리를 제어할 수 없다.
- auto.commit.interval.ms: 오프셋을 자동으로 커밋할 경우, 커밋되는 주기를 설정할 수 있다.

### 컨슈머에서 명시적으로 오프셋 커밋하기

- 메시지 처리 먼저, 오프셋 커밋은 나중에 해야 중복 처리를 회피할 수 있다.
- 커밋 빈도는 성능과 크래시 발생시 중복 개수 사이의 트레이드오프다.
- 컨슈머가 처리 도중 에러가 발생하면, 그 다음 레코드가 성공한다 하더라도 해당 레코드까지 오프셋을 커밋하면 안 된다. 따라서 재시도 가능한 에러가 발생했을 경우 다음 방법을 사용할 수 있다.
    1. 마지막으로 성공한 오프셋을 커밋하고, 나중에 처리해야 할 레코드를 버퍼에 저장하고, 컨슈머의 pause 메서드를 호출해서 추가적인 poll 호출이 데이터를 리턴하지 않도록 한 뒤, 레코드 처리를 계속한다.
    2. 별도의 토픽에 쓴 뒤 계속해서 진행한다.(데드 레터 큐 시스템과 비슷)
