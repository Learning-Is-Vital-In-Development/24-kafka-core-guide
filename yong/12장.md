# 12장 카프카 운영하기

## 12.1 토픽 작업

kafka-topics.sh 툴은 대부분의 토픽 작업을 쉽게 할 수 있음

클러스터 내 토픽 생성, 변경, 삭제, 조회 가능함

토픽 설정은 kafka-configs.sh로 가능

### 12.1.1 새토픽 생성

—topic : 생성 토픽명

—replication-factor : 유지되어야 할 레플리카 수

—partitions : 파티션의 수

### 12.1.2 토픽 목록 조회

—list

### 12.1.3 토픽 상세 내역 조회

—topics-with-overrides : 설정 중 클러스터 기본값을 재정의한 것이 있는 토픽을 보여줌

—exclude-internal : ‘__’ 로 시작하는 모든 토픽들을 결과에서 제외

—under-replicated-partitions : 1개 이상의 레플리카가 리더와 동기화되지 않고 있는 모든 파티션을 보여줌

—at-min-isr-partitios : 레플리카 수가 인-싱크 레플리카 최소값과 같은 모든 파티션을 보여줌

—under-min-isr-partitions : ISR 수가 쓰기 작업이 성공하기 위해 필요한 최소 레플리카 수에 미달하는 모든 파티션을 보여줌, 사실상 읽기 전용 모드

—unavailable-partitions : 리더가 없는 모든 파티션을 보여줌

### 12.1.4 파티션 추가

—alter

### 12.1.5 파티션 개수 줄이기

토픽의 파티션은 줄일 수 없음

### 12.1.6 토픽 삭제

—delete

## 12.2 컨슈머 그룹

kafka-consumer-groups.sh 툴을 사용

토픽을 읽고 있는 컨슈머 그룹을 관리하고 인사이트 얻을 수 있음

컨슈머 그룹 목록을 조회, 상세 내역, 삭제, 정보 초기화에 사용

### 12.2.1 컨슈머 그룹 목록 및 상세 내역 조회

—list

group : 컨슈머 그룹명

topic : 읽고 있는 토픽명

partition : 읽고 있는 파티션의 ID

current-offset : 컨슈머 그룹이 파티션에서 다음번에 읽어올 메시지의 오프셋

log-end-offset : 브로커 토픽 파티션의 하이 워터마크 오프셋 현재값

lag : 컨슈머의 current-offset과 브로커의 log-end-offset 간의 차이

consumer-id : 설정 된 client-id값을 기준으로 생성된 고유한 consumer-id

host : 컨슈머 그룹이 읽고 있는 호스트의 IP 주소

client-id : 컨슈머 그룹에서 속한 클라이언트를 식별하기 위해 클라이언에 설정된 문자열

### 12.2.2 컨슈머 그룹 삭제

—delete

### 12.2.3 오프셋 관리

—dry-run : 테스트 해볼 수 있는 명령어

—reset-offsets : 완전 리셋

## 12.3 동적 설정 변경

kafka-configs.sh가 주로 사용

cleanup.policy : conpact로 설정하면 키별로 가장 최근 메시지만 남겨두고 포틱의 모든 나머지 메시지들이 삭제(로그 압착)

compression.type : 메시지 배치를 디스크에 쓸 때 브로커가 사용하는 압축 코덱

delete.retention.ms : 삭제된 툼스톤 메시지를 보존하는 기간(밀리초). cleanup.policy가 compact로 설정되어 있는 토픽에만 유효

file.delete.delay.ms : 로그 세그먼트 파일과 인덱스를 디스크에 보존하는 기간(밀리초)

flush.messages : 토픽 메시지를 디스크로 쓰기 전에 수신할 메시지 개수

flush.ms : 토픽 메시지를 디스크로 쓰기 전에 기다리는 시간(밀리초)

follower.replication.throttled.replicas : 팔러워에 의해 복제 작업에 스로틀이 걸려야 할 레플리카의 목록

index.interval.bytes : 로그 세그먼트의 인덱스 항목 간에 쓸 수 있는 메시지의 바이트 크기

leader.replication.throttled.replica : 리더에 의해 복제 작업에 스로틀이 걸려야 할 레플리카의 목록

max.compaction.lag.ms : 로그가 압착되기 전 메시지가 대기할 수 있는 최대 시간

max.message.bytes : 토픽에 저장되는 메시지의 최대 크기(바이트)

message.downconverstion.enable : 클라이언트가 요청할 경우 약간의 오버헤드를 감수하고 메시지 형식 버전을 예전 버전으로 변환해서 내보냄

message.format.version : 브로커가 메시지를 디스크에 쓸 때 사용할 메시지 형식 버전, 반드시 유효한 API 버전 번호여야 함

message.timestamp.type : 메시지를 디스크에 쓸 때 사용할 타임스탬프 유형, 클라이언트에 의해 지정된 타임스탬프 값을 사용할 경우 CreateTime, 메시지가 브로커에 의해 파티션에 쓰여지는 시각을 사용할 경우 LogAppendTime

min.cleanable.dirty.ratio : 토픽의 파티션을 압착 시도하는 빈도, 로그 세그먼트 전체 개수에 대해 압착되지 않은 로그 세그먼트의 개수의 비율을 나타냄. cleanup.plocy가 compact로 설정되어 있는 토픽에만 유효

min.compaction.lag.ms : 메시지가 압착되지 않은 채로 남아있을 수 있는 최소 시간

min.insync.replicas : 토픽이 사용 가능한 것으로 간주되기 위해 동기화되어야 하는 토픽 파트션별 레플리카 수의 최소 값

preallocate : true로 설정되어 있을 경우, 새 세그먼트가 사용되기 전에 미리 할당됨

retention.bytes : 보존할 메시지의 양(바이트)

retention.ms : 메시지를 보존하는 시간(밀리초)

segment.bytes : 파티션의 로그 세그먼트 하나에 쓰여지는 메시지의 양(바이트)

segment.index.bytes : 로그 세그먼트 인덱스 하나의 최대 크기(바이트)

segment.jitter.ms : 로그 세그먼트를 새로 생성할 떄 segment.ms에 랜덤하게 더해주는 밀리초 값의 최대값

segment.ms : 각 파티션의 로그 세그먼트를 새로 생성하는 빈도(밀리초)

unclean.leader.election.enable : false로 설정할 경우, 해당 토픽에 대해 언클린 리더 선출이 허용되지 않음

### 12.3.2 클라이언트와 사용자 설정 기본값 재정의하기

consumer_bytes_rate : 하나의 클라이언트 ID가 하나의 브로커에서 초당 읽어올 수 있는 메시지의 양(byte)

producer_bytes_rate : 하나의 클라이언트 ID가 하나의 브로커에 초당 쓸 수 있는 메시지의 양(byte)

controller_mutations_rate : 컨트롤러의 변경률, 사용가능한 토픽 생성, 파티션 생성, 토픽 삭제 요청의 양 이 값은 생성되거나 삭제된 파티션 수 단위로 집계됨

request_percentage : 사용자 혹은 클라이언트로부터의 요청에 대한 쿼터 윈도우 비율((num.io.threads + num.neetwork.threads) x 100%에 대한 비율로 집계)

@ 팁

클라이언트 ID vs 컨슈머 그룹

클라이언트 ID와 컨슈머 그룹명은 같을 필요가 없음 

각 컨슈머 그룹의 클라이언트 ID는 컨슈머 그룹을 식별할 수 있는 값으로 잡아는게 좋음

### 12.3.3 브로커 설정 기본값 재정의하기

min.insync.replicas : 프로듀서의 acks 설정 값이 all로 잡혀 있을 때 쓰기 요청에 응답이 가기 전에 쓰기가 이루어져야 하는 레플리카 수의 최소값을 결정

unlean.leader.election.enable : 리더 선출 되었을 경우 데이터 유실이 발생하는 레플리카를 리더로 선출할 수 있게 해줌

max.connections : 브로커에 연결할 수 있는 최대 연결 수 
세밀하게 하려면 max.connections.per.ip.max.connections.per.ip.ovverrides 이용

### 12.3.4 재정의 된 설정 상세 조회

### 12.3.5 재정의 된 설정 삭제

—delete-config

—alter

## 12.4 쓰기 작업과 읽기 작업

kafka-console-consumer.sh

kafka-console-producer.sh

### 12.4.1 콘솔 프로듀서

1. 쓰기

—batch-size : 하나의 배치로 전달되어야 할 메시지의 수

—timeout : 프로듀서가 비동기 모드로 작동중일 때, 메시지 배치를 쓰기 전에 기다리는 최대 시간 지정

—compression-codec {압축코덱} : 메시지를 쓸 떄 사용할 압축 코덱 gzip → none, gipz, snappy, zstd, lz4 

—sync : 메시지를 동기적으로 쓴다

1. 읽기

ignore.error → true : false이고 parse.key가 true인 상태에서 키 구분자가 정의되어 있지 않을 경우 예외 발생

parse.key → true : 키 값을 항상 null로 고정하고 싶으면 false

key.separator → 탭 문자 : 메시지 키와 밸류를 구분할 때 사용되는 구분자

### 12.4.2 콘솔 컨슈머

—topic : 토픽의 일므 지정

—whitelist : 읽어오고자 하는 모든 토픽 이름과 매치되는 정규식을 지정

1. 컨슈머 설정 옵션 사용

—formatter {클래스 이름} : 메시지를 바이트 뭉치에서 문자열로 변환하기 위해 사용될 메시지 포메터
→ kafka.tools.DefaultMessageFormatter

—from-beginning : 지정된 토픽의 가장 오래된 오프셋부터 메시지를 읽어온다, 지정하지 않으면 가장 최근 오프셋부터 읽어옴

—max-messages {정수값} : 종료 되기 전 읽어올 최대 메시지 수 

—partition {정수값} : 지정된 ID의 파티션에서만 읽어옴

—offset : 읽어오기 시작할 오프셋, earliest로 지정할 경우 맨 처음부터, latest로 지정할 경우 가장 최신값부터 읽어옴

—skip-message-on-error : 메시지에 에러가 있을 경우 실행을 중단하는게 아니라 그냥 넘어감, 디버깅용

1. 메시지 포메터 옵션

kafka.tools.LogginMessageFormatter : 표준 출력이 아니라 로거를 사용해서 메시지 출력함

kafka.tools.ChecksumMessageFormatter : 메시지의 체크섬만 출력

kafka.tools.NoOpMessageFormatter : 메시지를 읽어오되 아무것도 출력하지 않음

## 12.5 파티션 관리

리더 레플리카를 다시 선출하는 툴

파티션을 브로커에 할달해주는 저수준 툴

### 12.5.1 선호 레플리카 선출

kafka-leader-election.sh : 카프카 클러스터에 균형이 맞지 않을 경우, 선호 레플리카 선출을 실행할 수 있고 클러스터 컨트롤러로 하여금 파티션에 대해 가장 적절한 리더를 고르도록 함
클라이언트는 리더 역할이 변하는 것을 자동으로 감지할 수 있기 때문에 리더 역할이 옮겨간 브로커로 요청을 보낼 수 있음

### 12.5.2 파티션 레플리카 변경하기

- 자동으로 리더 레플리카를 분산시켜 주었는데도 브로커간 부하가 불균등할 때
- 브로커가 내려가서 파티션이 불완전 복제되고 있을 때
- 새로 추가된 브로커에 파티션을 빠르게 분산시켜주고 싶을 때
- 토픽의 복제 팩터를 변경해주고 싶을 경우

—additional : 지정된 재할당 작업이 현재 진행중인 재할당 작업에 추가되도록 함

—disable-rack-aware : 랙 인식 기능으로 인해 파티션 이동 안의 결과물이 불가능할 수도 있고 필요하다면 이 플래그를 사용해서 랙 인식 기능을 끌 수 있음

—throttle : 초당 바이트 수로 나타냄, 파티션 재할당은 일정하게 유지되면 메모리 페이지 캐시사용량과 네트워크, 디스크 I/O를 변화시키는 만큼 클러스터의 성능에 큰 영향을 미침
