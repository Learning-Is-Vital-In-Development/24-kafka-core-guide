# 7장 신뢰성 있는 데이터 전달

신뢰성은 시스템의 속성 중 하나다 

카프카의 신뢰성 보장은 전체 시스템과 활용 사례를 염두 할 필요가 있음

신뢰성에서 유연성 절충 고려

1. 무엇보다 신뢰성 우선
2. 신뢰성보다 속도를 우선

카프카를 사용하다 시스템의 신뢰성이 높다고 착각해서 실수하는 경우 있음

신뢰성이 어떤것이 있는지 어떤 의미를 갖는지를 논의할 예정

## 7.1 신뢰성 보장

데이터 베이스의 ACID를 준수는 어떠한 행동을 보장한다는 의미가 있음

A : atomicity

C : consistency

I : isolation

D : durability

카프카에서도 이러한 보장을 통해서 무엇을 약속하는지, 서로 다른 조건에서 어떻게 작동하는지 적확히 알 수 있음

카프카가 보장

- 카프카는 파티션 안의 메시지들 간에 순서를 보장
- 클라이언트가 쓴 메시지는 모든 인-싱크 레플리카의 파티션에 쓰여진 뒤에야 ‘커밋’된 것으로 간주된다
프로듀서는 메시지가 완전히 커밋된 다음 응답이 올지, 리더에게 쓰여진 다음 응답이 올지 아니면 네트워크로 전송된 다음 바로 응답이 올지를 선택할 수 있다
- 커밋 된 메시지들은 최소 1개의 작동 가능한 레플리카가 남아 있는 한 유실되지 않는다
- 컨슈머는 커밋된 메시지만 읽을 수 있다

신뢰성 있는 시스템을 구축하는 데는 트레이드 오프가 있는 법이고, 카프카는 이러한 트레이드 오프들을 조절할 수 있도록 개발자나 운영자가 설정 매개변수를 조절함으로써 어느 정도의 필요한지를 결정할 수 있도록 개발

- 신뢰성과 일관성이 우선인지
- 가용성이 우선인지
- 높은 처리량
- 낮은 지연
- 하드웨어 비용
- 기타 고려 사항

## 7.2 복제

카프카의 복제 메커니즘은 파티션별로 다수의 레플리카를 유지한다는 특성과 함께 카프카의 신뢰성 보장의 핵심이라고 할 수 있다

하나의 메시지를 여러 개의 레플리카에 씀으로써 카프카는 크래시가 나더라도 메시지의 지속성을 유지한다.

각 카프카 토픽은 기본적인 데이터 구성 요소인 파티션으로 이루어지며 하나의 파티션은 하나의 디스크에 저장됨

1. 이벤트 들의 순서를 보장
2. 온라인 상태, 오프라인 상태일 수 있음
3. 각 파티션은 다수의 레플리카를 가질 수 있으며 그 중 리더 선출
4. 모든 이벤트들은 리더 레플리카에 쓰이고 읽힘
5. 다른 레플리카들은 리더와 동기화를 맞춤
6. 리더가 불능 상태 시 인-싱크 레플리카 중 하나가 새리더가 됨

인-싱크 상태 간주 조건

- 주키퍼와 활성 세션이 있다. 최근 6초 사이(설정 가능)에 주키퍼로 하트비트를 전송
- 최근 10초 사이(설정 가능) 리더로부터 메시지를 읽어왔다
- 최근 10초 사이에 리더로부터 읽어 온 메시지들이 가장 최근 메시지이다. 팔로워가 리더로부터 메시지를 받고 있는 것만으로는 부족하다. 최근 10초 사이(설정 가능) 랙이 없었던 적이 최소 한번은 있어야 한다

위 조건에 부합하지 않으면 아웃-오브-싱크상태로 간주

다시 연결되어 리더의 최근 메시지까지 따라잡으면 다시 인-싱크-레플리카로 간주

## 7.3 브로커 설정

메시지 저장 신뢰성 관련된 카프카의 작동을 변경시키는 브로커의 설정 매개변수는 3가지 있음

### 7.3.1 복제 팩터 : replication.factor

1. default.replication.factor : 자동으로 생서되는 토픽들에 적용되는 브로커 단위 설정
2. 복제 팩터가 3이라고 가정 - 자연히 복제 팩터 역시 변경이 가능
3. N-1개의 브로커가 중단되더라도 토픽의 데이터를 읽거나 쓸 수 있음
- 복제 팩터가 클수록 가용성과 신뢰성으 늘어나고 장애 발생 가능성도 줄어듬
- 반대로 N개의 브로커가 필요하고 N개의 복사본을 저장할 N배의 디스크 공간 필요로 비용 증가
- 몇 가지의 핵심 고려 사항
    1. 가용성 : 레플리카가 하나 뿐이라면 브로커 재시작만으로도 작동 불능에 빠짐 
    2. 지속성 : 각 레플리카는 파티션 안의 모든 데이터의 복사본이며 레플리카가 하나뿐이고 어떠한 이유에서 디스크가 사용 불가능하게 될 경우 해당 파티션의 모든 데이터는 유실 
    3. 처리량 : 레플리카가 추가될 때마다 브로커간 트래픽 늘어남
    하나뿐이라면 10Mbps, 두개라면 10Mbps, 세개라면 20Mbps, 5개라면 40Mbps
    4. 종단 지연 : 쓰여진 메시지를 컨슈머가 읽을 수 있으려면 모든 인-싱크 레플리카에 복제 되어야 함
    레플리카 수가 더 많을수록 이들 중 하나가 느려짐으로써 컨슈머까지 함꼐 느려질 가능성이 높아짐
    특정한 브로커가 느려지면 해당 브로커를 사용하는 모든 클라이언트 역시 복제 팩터에 무관하게 느려짐
    5. 비용 : 복제 팩터를 3미만으로 잡아주는 가장 일반적인 이유
    많은 레플리카를 가질수록 저장소와 네트워크에 들어가는 비용 역시 증가
    많은 저장소 시스템들이 각 블록을 3개로 복제해서 저장하는 경우가 많이 떄문임
    카프카를 설정 할 때 복제 팩터를 2로 잡아줌으로써 저장 비용을 줄일 수 있지만 3인경우에 비해 가용성은 떨어짐

부가 설명

- 레플리카 위치도 중요함
- 카프카는 언제나 같은 파티션의 레플리카들을 서로 달느 브로커에 저장함
- 만약 같은 파티션의 모든 레플리카들이 같은 랙에 설치되어 있는 브로커들에 저장되었는데 랙 스위치가 오작동할 경우
    - 복제 팩터 하고는 상관없이 해당 파티션은 사용할 수 없게 됨
    - 사고 방지를 위해 브로커들을 서로 다른 랙에 배치한 뒤 broker.rack 설정 매개변수에 랙 이름을 잡아 줄 것을 권장하며 설정으로 서로 다른 랙에 분산되어 저장되어 가용성을 높일 수 있음

### 7.3.2 언클린 리더 선출

1. unclean.leader.election.enable(false) : 브로커 단위(클러스터 단위)에서만 가능 
2. 클린의 정의 : 커밋 된 데이터에 아무런 유실이 없음을 보장하는 리더 선출
- 작동 불능에 빠진 리더 외에 인-싱크 레플리카가 없다면 어떻게 될까
    - 파티션에 3개의 레플리카가 있고 팔로워 2개가 작동 불능에 빠졌을 경우
        1. 프로듀서는 리더에 쓰기 작업을 계속할 것이므로 모든 메시지는 커밋되고 응답이 간다
        2. 이 와중에 브로커가 크래시 나면 리더를 사용할 수 없게 되고 아웃-오브-싱크 레플리카 중 하나가 먼저 시작 됨
        3. 해당 파티션의 유일한 사용 가능한 레플리카가 아웃-오브-싱크 레플리카 됨
    - 파티션에 3개의 레플리카가 있고, 네트워크 문제 발생으로 팔로워 2개의 복제 작업이 뒤쳐졌을 경우
        1. 복제 작업이 계속되지만 아웃-오브-싱크 상태는 아님
        2. 리더 레플리카는 유일한 인-싱크 레플리카로서 계속해서 메시지를 받음
        3. 리더가 작동 불능에 빠지면 리더가 될 수 있는 아웃-오브-싱크 레플리카밖에 없음
    - 아웃-오브-싱크 레플리카가 새 리더가 될 수 없도록 한다면, 예전 리더(마지막 인-싱크 레플리카)가 복구될 때까지 해당 파티션은 오프라인 상태가 됨
    - 아웃-오브-싱크 레플리카가 새 리더가 될 수 없도록 한다면, 새 리더가 동기화를 못 한 사이 예전 리더에 쓰여졌던 모든 메시지들이 유실되고 컨슈머 입장에서서의 일관성 역시 어느정도 깨진다
- 아웃-오브-싱크 레플리카는 리더가 될수 없도록 기본 설정 되어 있고 유실에 있어 가장 좋은 보장을 제공하는 만큼 가장 안전한 옵션임

### 7.3.3 최소 인-싱크 레플리카

min.insync.replicas 

토픽당 3개의 레플리카를 설정하더라도 하나만 남을 수 있고 작동 불능에 빠질 경우

가용성과 일관성 사이에서 하나를 골라야 한다

min.insync.replicas = 2 인 경우 프로듀서들은 3개 중 최소 2개가 인-싱크 상태인 파티션에만 쓸 수 있음

만약 세개 중 두개가 불능에 빠지면 브로커는 더 이상 쓰기 요청을 받을 수 없고 컨슈머는 계속해서 읽을 수 있다 

인-싱크 레플리카 하나만 남을 경우 해당 레플리카는 사실상 읽기 전용이 됨

이 때 언클린 리더 선출이 발생하면 사라질 데이터를 쓰거나 읽는, 바람직하지 못한 상황을 방지 

읽기 전용 상태를 회복하려면 두 개의 사용 불능 레플리카 중 하나를 복구 시킨 뒤 레플리카의 상태를 따라잡아서 인-싱크 상태로 들어갈 때까지 기다려야 함

### 7.3.4 레플리카를 인-싱크 상태로 유지

아웃-오브-싱크 레플리카는 전반적인 신뢰성을 낮추므로 가능한 한 피할 필요가 있음

아웃-오브-싱크가 발생 두가지 경우

1. 주키퍼와의 연결이 끊어지거나 
2. 리더 업데이트 내역을 따라가는데 실패해서 복제 랙이 발생하거나

카프카 클로스터의 민감도 조절할 수 있는 설정 두 가지

1. zookeeper.session.timeout : 브로커가 주키퍼로 하트비트 전송을 멈출 수 있는 최대 시간 정의
    - 이 간격 안에만 하트비트를 보내면 주키퍼는 브로커가 죽었다고 판단하지 않음
    - default : 18초
2. replica.lag.time.max.ms : 설정된 값보다 더 오랫동안 리더로부터 데이터를 읽어오지 못하거나 리더에 쓰여진 최신 메시지를 따라잡지 못하고 동기화가 풀림
    - default : 30초

### 7.3.5 디스크 저장하기

카프카는 메시지를 받은 레플리카에만 의존

디스크에 저장되지 않은 메시지도 응답 함

**카프카는 세그먼트를 교체할 때(기본1G)와재시작 직전에만 메시지를 디스크로 플러시하고 그외에는 리눅스의 페이지 캐시 기능에 의존함**

발상의 배경에는 각각 데이터의 복제본을 가지고 있는, 서로 다른 랙이나 가용 영역에 위치한 세 대의 장비가 리더의 디스크에 메시지를 쓰는 것보다 더 안전하다는 판단

→ 서로 다른 랙이나 가용 영역에서 동시에 장애가 발생할 가능성은 거의 없음

flush.messages : 디스크에 저장되지 않은 최대 메시지 수 

flush.ms : 얼마나 더 자주 디스크에 저장할지 

## 7.4 신뢰성 있는 시스템에서 프로듀서 사용하기

- 케이스1
    - 토픽별 3개의 레플리카를 가지도록 브로커를 설정한 상태에서 언클린 리더 선출 기능을 끈다
    1. 카프카 클러스터에 커밋된 메시지는 유실되지 않음
    2. 프로듀서가 메시지를 보낼 때 acks=1 설정으로 보내도록 설정
    3. 프로듀서에서 메시지를 전송해서 리더에 쓰였지만 아직 인-싱크 레플리카에 반영되지 않은 상태
    4. 리더가 프로듀서에게 “메시지가 성공적으로 쓰여졌다”라고 응답을 보낸 직후 크래시 발생으로 복제 실패
    5. 다른 레플리카들은 여전히 인-싱크 상태로 간주(아웃-오브-싱크 레플리카 판정은 설정에 따라 시간 소요)
    6. 그 중 하나가 리더가 됨
    7. 메시지가 레플리카에 쓰여지지 않은 만큼 해당 메시지는 유실됨
    8. 메시지를 쓰고 있는 애플리케이션 입장에서는 성공적으로 쓰여졌다고 착각
    9. 어떤 컨슈머도 이 메시지를 보지 못한 만큼(레플리카 입장에서는 본 적도 없는 메시지이기 때문에 커밋된게 아님)
    10. 시스템의 일관성 유지
    11. 하지만 프로듀서 입장에서는 메시지는 유실됨
- 케이스 2
    - 토픽별로 3개의 레플리카를 가지도록 브로커를 설정한 상태에서 언클린 리더 선출 기능을 끈다
    1. 앞의 실수에서 배워서 acks=all 설정으로 메시지 전송 시작
    2. 카프카에 메시지를 쓰려고 하는데 쓰고 있는 파티션의 리더 브로커가 크래시가 나서 새리더는 아직 선출중이라는 가정
    3. 카프카는 “Leader not Available”. 응답을 보냄
    4. 프로듀서가 올바르게 에러를 처리하지 않고 쓰기가 성공할 때까지 재시도도 하지 않을 경우, 메시지는 유실 될 수 있음
    5. 브로커도 메시지를 받지 않은 상황
    6. 컨슈머들 역시 메시지를 받은 적이 없기에 일관성의 문제가 아님
    7. 프로듀서가 이 에러를 정확히 처리해주지 않을 경우, 메시지 유실을 초래할 수 있음

신경써야 할 요소 두 가지

- 신뢰성 요구 조건에 맞는 올바른 acks 설정
- 설정과 코드 모두에서 에러를 올바르게 처리

### 7.4.1 응답 보내기

프로듀서는 세 가지 응답

1. acks=0
    - 프로듀서가 네트워크로 메시지를 전송한 시점에서 메시지가 카프카에 성공적으로 쓰여진 것으로 간주
    - 전송하는 객체가 직렬화될 수 없거나 네트워크 카드가 오작동할 경우 여전히 에러를 받겠지만, 파티션이 오프라인이거나, 리더 선출이 진행중이거나, 심지어 전체 카프카 클러스터가 작동 불능인 경우 에러가 발생하지 않음
    - 지연은 낮지만 종단 지연은 개선되지 않음
2. acks=1
    - 리더가 메시지를 받아서 파티션 데이터 파일에 쓴 직후 응답 또는 에러를 보낸다는 것을 의미
    - 일부 메시지가 리더에 성공적으로 쓰여져서 클라이언트로 응답이 긴 상태에서 미처 팔로워로 복제가 완료되기 전에 리더가 정지하거나 크래쉬 날 경우 데이터가 유실 될 수 있음
    - 메시지를 복제하는 속도보다 더 빨리 리더에 쓸 수 있기 때문에 불완전한 복제 파티션이 발생
    - 리더 입장에서는 복제가 완료되기 전에 프로듀서에게 응답 먼저 함
3. acks=all
    - 리더가 인-싱크 레플리카가 메시지를 받아갈 때까지 기다렸다가 응답하거나 에러를 보낸다는 것을 의미
    - min.insync.replicas 설정과 함께, 응답이 오기 전까지 얼마나 많은 레플리카에 메시지가 복제될것인지를 조절
    - 가자 완전한 옵션이며 프로듀서는 메시지가 완전히 커밋 될 때까지 계속해서 메시지를 재전송함
    - 프로듀서 지연이 가장 길어지는 옵션이기도 하며 프로듀서는 모든 인-싱크 레플리카가 메시지를 받을 때까지 기다린 뒤에야 해당 메시지 배치에 완료 표시를 하고 작업을 진행

### 7.4.2 프로듀서 재시도 설정하기

프로듀서 에러 처리 두 가지

1. 프로듀서가 자동으로 처리하는 에러
    - 재시도 가능한 에러를 처리 함
    - 프로듀서가 브로커에 메시지를 전송하면 브로커는 성공 혹은 에러 코드를 리턴 할 수 있음
    - 에러 코드 두 분류
        1. 전송을 재시도하면 해결될 수 있는 것 : 
            1. LEADER_NOT_AVAILABLE 에러 코드 리턴 시 전송 재시도
            2. 아마도 새로운 브로커가 선출된 상황이며 두번쨰는 성공할꺼임
        2. 전송을 재시도하면 해결될 수 없는 것
            1. INVALID_CONFIG 예외 리턴할 경우
            2. 재전송한다고 해서 설정이 변경되지 않음
2. 프로듀서 라이브러리로 사용하는 개발자 처리하는 에러

delivery.timeout.ms : 메시지 전송을 포기할 때까지 대기할 수 있는 시간을 지정

프로듀서는 이 시간 간격 내에 있는 한 메시지 전송을 계속 재시도

전송 실패 한 메시지를 재시도하는건 중복 될 위험을 내포함

재시도와 주의 깊은 에러 처리는 각 메시지가 ‘최소 한번’ 저장되도록 보장할 수는 있지만 ‘정확히 한 번’은 보장할 수 없음

enable.idempoence=true 설정을 잡아주어 프로듀서가 추가적인 정보를 레코드에 포함할 수 있도록 하며 브로커가 재시도로 인해 중복된 메시지를 건너뛸 수 있음

### 7.4.3 추가적인 에러 처리

- 메시지 크기에 관련되었거나 인가 관련 에러와 같이 재시도가 불가능한 브로커 에러
- 메시지가 브로커에 전송되기 전에 발생한 에러(직렬화 과정에서 발생한 에러)
- 프로듀서가 모든 재전송 시도를 소진해써나, 재시도 과정에서 프로듀서가 사용하는 가용 메모리가 메시지로 가득 차서 발생하는 에러
- 타임 아웃

## 7.5 신뢰성 있는 시스템에서 컨슈머 사용하기

모든 인-싱크 레플리카에 쓰여진 다음에 읽을 수 있음

컨슈머는 일관성이 보장되는 데이터만 읽음

컨슈머가 해야 할 일은 어느 메시지까지를 읽었고 어디까지는 읽지 않았는지를 추적하는 것

메시지를 읽는 도중에 누락되지 않게 하기 위해서 필수

카프카 컨슈머가 누락없이 언제나 새로운 데이터를 올바르게 읽어오는 순서

1. 파티션으로부터 데이터를 읽어 올 때, 
2. 컨슈머는 메시지를 배치 단위로 읽어온 뒤,
3. 배치별로 마지막 오프셋을 확인한 뒤,
4. 브로커로부터 받은 마지막 오프셋 값에서 시작하는 다른 메시지 배치를 요청함

특정 컨슈머가 작동을 정지하면 다른 컨슈머 입장에서는 어디서부터 작업을 재개해야 할지 알아야 할 필요가 있음

1. 이전 컨슈머가 정지하기 전에 마지막으로 읽은 오프셋은 무엇인가
2. ‘다른’ 컨슈머는 아예 별도의 컨슈머일 수도 있지만, 단순히 기존 컨슈머가 재시작한 것일 수도 있음
3. 어떤 컨슈머이든 정지한 컨슈머가 읽어오고 있던 파티션을 가져갈 것이고 어느 오프셋부터 작업을 시작해야 하는지는 알아야 함
4. 컨슈머가 읽어온 오프셋을 ‘커밋’해야 하는 이유가 여기에 있다
5. 읽고 있는 각 파티션에 대해 어디까지 읽었는지를 저장해 둬야 해당 컨슈머나 다른 컨슈머가 재시작한 뒤에도 어디서부터 작업을 계속해야 할지 알 수 있음
6. 컨슈머가 메시지를 누락할 수 있는 경우는 대개 읽기는 했지만 아직 처리는 완료되지 않은 이벤트들의 오프셋을 커밋하는 경우
7. 이렇게 하면 다른 컨슈머가 작업을 물려받았을 때 이 메세지들은 건너뛰게 되므로 영원히 처리 되지 않음
8. 오프셋이 언제 어떻게 커밋되는지에 대해 신경써야 하는 것이 중요한 이유임

@ 커밋된 메시지 vs 커밋 된 오프셋

커밋 된 메시지란 모든 인-싱크 레플리카에 쓰여져서 컨슈머가 읽을 수 있는 메시지를 의미

커밋된 오프셋이란 컨슈머가 특정 파티션 어느 오프셋까지의 모든 메시지를 받아서 처리를 완료했는지 의미

### 7.5.1 신뢰성 있는 처리를 위해 중요한 컨슈머 설정

설정 4가지 

1. group.id
2. auto.offset.rest
3. enable.auto.commit
4. auto.commit.interval.ms

### 7.5.2 컨슈머에서 명시적으로 오프셋 커밋하기

데이터를 신뢰성 있게 다루는 컨슈머를 개발할 때 고려해야 할 중요한 사항들

1. 메시지 처리 먼저, 오프셋 커밋은 나중에
2. 커밋 빈도는 성능과 크래시 발생 시 중복 개수 사이의 트레이드오프다
3. 정확한 시점에 정확한 오프셋을 커미사하자
4. 리밸런스
5. 컨슈머는 재시도를 해야 할 수도 있다
6. 컨슈머가 상태를 유지해야 할 수도 있다

## 7.6 시스템 신뢰성 검증하기

설정 검증, 애플리케이션 검증, 환경에 배포된 애플리케이션 모니터링

### 7.6.1 설정 검증하기

- 우리가 선택한 구상이 요구 조건을 충족시킬 수 있는지 확인하는 데 도움이 된다
- 시스템의 예상 작동을 추론해 보기 위한 좋은 방법이다.
카프카는 이러한 검증 작업을 위한 두 개의 중요한 툴을 포함
1. org.apache.kafka.tools 패키지에는 VerifiableProducer(검증용 프로듀서), VerifiableConsumer(검증용 컨슈머) 플래스가 포함되어 있고 각각은 명령줄 툴 형태로든 자동화된 테스팅 프레임워크에 포함된 형태로든 실행 가능

검증용 프로듀서를 사용해서 1에서부터 우리가 선택한 값까지의 숫자를 포함하는 메시지를 순서대로 쓴다 

acks, retries, [delivery.timeout.ms](http://delivery.timeout.ms) 등이 설정 값을 잡아줄 수 있고 메시지를 쓰는 속도 역시 정할 수 있음

어떤 테스트를 할 것인지 고려 사항

1. 리더 선출 : 리더를 정지시키면 어떻게 될까? 프로듀서와 컨슈머가 평상시처럼 작동을 재개하는데까지 얼마나 걸릴까?
2. 컨트롤러 선출 : 컨트롤러가 재시작한 뒤 시스템이 재개되는 데 얼마나 걸릴까?
3. 롤링 재시작 : 메시지 유실 없이 브로커들을 하나씩 재시작시킬 수 있을까?
4. 언클린 리더 선출 테스트 : (각 레플리카의 동기화가 풀리도록 하기 위해) 한 파티션의 모든 레플리카들을 하나씩 중단시킨 다음 아웃-오브-싱크 상태가 된 브로커를 시작시키면 어떻게 될까? 작업을 재개하려면 어떻게 해야 할까? 이것은 용인할 수 있는 수준인가?

1. 하나의 시나리오를 고른 뒤 검증용 프로듀서를 실행시키고, 
2. 검증용 컨슈머를 실행시키고,
3. 해당 시나리오대로 실행해 본다

→ 데이터를 써넣고 있는 파티션의 리더를 정지시킨다. 만약 잠깐 중단되었다가 메시지 유실 없이 정상적으로 작동이 재개될 거라고 예상했다면, 프로듀서가 쓴 메시지 수와 컨슈머가 읽어 온 메시지 수가 맞는지를 확인해 봐야 함

### 7.6.2 애플리케이션 검증하기

애플리케이션의 통합 테스트를 수행할 것을 권장하며 장애 상황에 대해 테스트 수행할 것을 권장함

- 클라이언트가 브로커 중 하나의 연결이 끊어짐
- 클라이언트와 브로커 사이의 긴 지연
- 디스크 꽉 참
- 디스크 멈춤
- 리더 선출
- 브로커 롤링 재시작
- 컨슈러 롤링 재시작
- 프로듀서 롤링 재시작

아프카 카프카는 장애 주입을 위한 자체적인 프레임 워크인 트록도르(trogdor)  테스트 프레임워크를 포함함

각 상황별로 우리는 예상 작동을 가지고 있음

이제 실제로 어떻게 되는지를 확인할 수 있도록 테스트 실행함

### 7.6.3 프로덕션 환경에서 신뢰성 모니터링하기

카프카나 자바 클라이언트들은 클라이언트 쪽 상태와 이벤트를 모니터링할 수 있게 해주는 JMX 지표를 포함함

신뢰성 측면에서 가장 중요한 두 지표는 레코드별 에러율과 재시도율임(초단위 평균값)
