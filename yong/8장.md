# 8. ‘정확히 한 번’ 의미 구조

최소 한번 : 카프카 브로커의 응답이 곧 커밋으로 간주되며, 유실되지 않음을 보장)

→ 하지만 메시지 중복 가능성은 유효함

→ 현실에서 사용되는 대부분의 애플리케이션들은 메시지를 읽는 애플리케이션이 중복 메시지를 제거할 수 있도록 메시지에 고유 식별자를 포함한다

정확히 한 번 의미 구조는 두 개의 핵심 기능

- 멱등적 프로듀서 : 프로듀서 재시도로 인해 발생하는 중복을 방지
- 트랜잭션 의미 구조 : 스트림 처리 애플리케이션에서 ‘정확히 한번’ 처리를 보장

## 8.1 멱등적 프로듀서

데이터베이스에서 멱등적이란

1. update t set x=x+1 where y = 5  → 멱등적이지 않음
2. update t set x=18 where y =5 → 멱등적임

‘정확히 한번’(=멱등적 구조) 이 아니라 ‘최소 한번’의미 구조를 가지도록 프로듀서를 설정하면 메시지 전송을 재시도함으로써 메시지가 최소 한 번 이상 도착할 수 있는 불확실성이 존재함

발생할만한 케이스

1. 파티션 리더가 프로듀서로부터 레코드를 받아서 팔로워에게 성공적으로 복제한다
2. 프로듀서에게 응답을 보내기 전, 파티션 리더가 있는 브로커에 크래시가 발생한다.
3. 프로듀서 입장에서는 응답을 받지 못한 채 타임아웃이 발생하고, 메시지를 재전송한다.
4. 재전송 된 메시지가 새 리더에 도착한다. 하지만 이 메시지는 이미 저장되어 있다(결과적으로, 중복이 발생)

어떤 애플리케이션은 중복이 크게 문제 되지 않지만 재고가 안맞거나 재무재표가 잘못되거나 우산 주문한 고객에게 두개를 배송하는 문제가 발생할 수 있다

→ 카프카의 멱등적 프로듀서 기능은 자동으로 이러한 중복을 탐지하고 처리함

### 8.1.1 멱등적 프로듀서의 작동 원리

**멱등적 프로듀서 기능을 켜면 모든 메시지는 고유한 프로듀서 ID와 시퀀스 ID를 가짐**

두 값을 합치면 각 메시지의 고유한 식별자가 됨 

→ 각 브로커는 브로커에 할당 된 모든 파티션들에 쓰여진 마지막 5개 메시지들을 추적하기 위해 사용함

파티션별로 추적되어야 하는 시퀀스 넘버의 수를 제한하고 싶다면 프로듀서의 max.in.flights.request.per.connection 설정 값이 5 이하로 잡혀 있어야 함(기본 값 : 5)

받은 메세지를 또 받으면 예외를 발생시키고 해당 예외를 사용자에게 경보를 보내지 않음

프로듀서 클라이언트에서는 record-error-rate 지표값을 확인함으로써 에러 확인 가능

RequestMetrics 유형의 ErrorsPerSEc 지표값에 기록됨

브로커는 2번 메시지의 다음은 3을 기대하지만 27일 올 경우 브로커는 ‘out of order sequence number’ 에러 발생 시킴

→ 만약 트랜잭션 기능 없이 멱등적 프로듀서만 사용하고 있다면 해당 에러는 무시해도 좋음

@ 주의

‘out of order sequence number’ 에러가 발생한 뒤에도 프로듀서가 정상 동작한다면, 이 에러는 보통 프로듀서와 브로커 사이에 메시지 유실이 있었음을 의미

→ 2번 메시지 뒤 27번 메시지를 받았드면 3~26번 메시지 사이에 뭔가 일어남

만약 로그에 에러가 찍힌다면 프로듀서와 브로커 설정을 재점검하고 프로듀서 설정이 고신뢰성을 위해 권장되는 값으로 잡혀 있는지 아니면 언클린 리더 선출이 발생했는지의 여부를 확인

모든 분산 시스템과 마찬가지로, 작동이 실패했을 경우 멱등적 프로듀서가 어떻게 처리하는지를 생각해보는 것은 의미가 있음

프로듀서 재시작과 브로커 장애의 두 가지 경우

1. 프로듀서 재시작 

프로듀서에 장애가 발생할 경우, 보통 새프로듀서를 생성해서 장애가 난 프로듀서를 대체

→ 사람이 직접 장비를 재시작하거나 쿠버네티스와 같이 자동 장애복구 기능을 제공하는 복잡한 프레임워크일 수 있음

재시작을 하게 되었을 때 멱등적 프로듀서 기능 on, off 여부에 따른 케이스

- **프로듀서가 시작될 때 멱등적 프로듀서 기능이 커져 있을 경우**

→ 프로듀서는 초기화 과정에서 카프카 브로커로부터 프로듀서 ID를 생성 받음 

- **프로듀서가 시작될 때 멱등적 프로듀서 기능이 커져 있지 않을 경우**

→ 프로듀서를 초기화할 때마다 완전히 새로운 ID가 생성 됨

프로듀서에 장애가 발생해서 대신 투입된 새 프로듀서가 기존 프로듀서가 이미 전송한 메시지를 다시 전송할 경우,

브로커는 메시지에 중복이 발생 했음을 알아차리지 못함

(두 메시지가 서로 다른 프로듀서 ID와 시퀀스 넘버를 갖는 만큼 서로 다른 것으로 취급될 것임)

만약 기존 프로듀서가 작동을 멈췄다가 새 프로듀서가 투입된 뒤 작동을 재개해도 마찬가지임 

서로 다른 ID를 가진 서로 다른 프로듀서로 간주되는 만큼 기존 프로듀서는 좀비로 취급되지 않음

1. 브로커 장애

만약 브로커 장애가 발생할 경우, 

컨트롤러는 장애가 난 브로커가 리더를 맡고 있었던 파티션들에 대해 새 리더를 선출

새로 선출 된 리더는 기존 리더가 어느 시퀀스 넘버까지 쓰여졌는지 어떻게 알고 중복 메시지를 걸러내는가?

1. 리더는 새 메시지가 쓰여질 때마다 인-메모리 프로듀서 상태에 저장된 최근 5개의 시퀀스 넘버를 업데이트함
2. 팔로워 레플리카는 리더로부터 새로운 메시지를 복제할 때마다 자체적인 인-메모리 버퍼를 업데이트 함

→ 팔로워가 리더가 된 시점에는 이미 메모리 안에 최근 5개의 시퀀스 넘버를 가지고 있는것으로 아무 이슈나 지연 없이, 새로 쓰여진 메시지의 유효성 검증이 재개될 수 있음

이후 예전 리더가 돌아온다면 어떤 일이 벌어지는가?

1. 재시작 후에는 인-메모리 프로듀서 상태는 더 이상 메모리 안에 저장되어 있지 않다
2. 복구 과정에 도움이 되도록 브로커는 종료되거나 새 세그먼트가 생성될 때마다 프로듀서 상태에 대한 스냅샷을 파일 형태로 저장
3. 브로커가 시작되면 일단 파일에서 최신 상태를 읽어옴
4. 현재 리더로부터 복제한 레코드를 사용해서 프로듀서 상태를 업데이터함으로써 최신 상태를 복구
5. 해당 브로커가 다시 리더를 맡을 준비가 될 시점에는 최신 시퀀스 넘버를 가지게 됨

만약 브로커가 크래시 나서 최신 스냅샷이 업데이트 되지 않는다면 어떻게 될까?

1. 프로듀서 ID와 시퀀스 넘버는 둘 다 카프카 로그에 저장되는 메시지 형식의 일부임
2. 크래시 복구 작업이 진횅되는 동안 프로듀서 상태는 더 오래 된 스냅샷뿐만 아니라 각 파티션 최신 세그먼트의 메시지들 역시 사용해서 복구
3. 복구 작업이 완료되는 대로 새로운 스냅샷 파일이 저장

만약 메시지가 없다면 어떻게 될까

1. 보존 기한은 2시간인데 지난 두 시간동안 메시지가 하나도 들어조지 않은 토픽을 상상해 보자
(브로커가 크래시 날 경우, 프로듀서 상태를 복구하기 위해 사용할 수 있는 메시지 역시 없을 것이다)
2. 다행히, 메시지가 없다는 얘기는 중복이 없다는 이야기
3. 즉시 새 메시지를 받기 시작해서(프로듀서 상태가 없다는 경고가 로그에 찍힐 것이다)
4. 새로 들어오는 메시지들을 기준으로 프로듀서 상태를 생성함

### 8.1.2 멱등적 프로듀서의 한계

멱등적 프로듀서는 프로듀서의 내부 로직으로 인한 재시도가 발생할 경우 생기는 중복만 방지

동일한 메시지를 가지고 producer.sned()를 두번 호출하면 멱등적 프로듀서가 개입하지 않는 만큼 중복된 메시지 발생함

여러 갸의 인스턴스를 띄우거나 하나의 인스턴스에서 여러 개의 프러듀서를 띄우는 애플리케이션들에서 발생함

### 8.1.3 멱등적 프로듀서 사용법

enable.idempotence=true 

만약 프로듀서에 acks=all 설정이 이미 잡혀 있다면, 성능에는 차이가 없음

멱등적 프로듀서 활성화 시 변경 되는 것

- 프로듀서 ID를 받아오기 위해 프로듀서 시동 과정에서 API를 하나 더 호출
- 전송되는 각각의 레코드 배치에는 프로듀서 ID와 배치 내 첫 메시지의 시퀀스 넘버가 포함
(각 메시지의 시퀀스 넘버는 첫 메시지의 시퀀스 넘버에 변화량을 더하면 나옴)
이 새 필드들은 각 메시지 배치에 96비트를 추가함(프로듀서 ID는 long, 시퀀스 넘버는 integer타입)
대부분의 경우 작ㅇ버 부하에 어떠한 오버헤드도 되지 않음
- 브로커들은 모든 프로듀서 인스턴스에서 들어온 레코드 배치의 시퀀스 넘버를 검증해서 메시지 중복을 방지
- 장애가 발생하더라도 각 파티션에 쓰여지는 메시지들의 순서는 보장
max.in.flight.requests.per.connection 설정 값이 1보다 큰 값으로 잡혀도 마찬가지
(5는 기본값인 동시에 멱등적 프로듀서가 지원하는 가장 큰 값)

## 8.2 트랜잭션

트랜잭션 기능은 카프카 스트림즈를 사용해서 개발 된 애플리케이션에 정확성을 보장하기 위해 도입

스트림 처리 애플리케이션이 정확한 결과를 산출하도록 하기 위해, 각 입력 레코드는 정확히 한 번만 처리되어야 하며 그 처리 결과 역시(장애 상황에서도) 정확히 한 번만 반영되어야 한다.

아파치 카프카의 트랜잭션 기능은 스트림 처리 애플리케이션이 정확한 결과를 산출할 수 있도록 함

스트림 처리 애플리케이션의 기본 패턴 : 읽기-처리-쓰기 패턴에서 사용하도록 개발함

@ 트랜잭션은 근본적인 메커니즘의 이름이며 ‘정확히 한 번’ 의미 구조 혹은 ‘정확히 한 번’ 보장은 스트림 처리 애플리케이션의 작동을 가르킴

스파크 스트리밍이나 플링크와 같은 다른 스트림 처리 프레임워크의 경우 사용자에게 ‘정확히 한 번’ 의미 구조를 제공하기 위해 메커니즘을 사용

### 8.2.1 트랜잭션 활용 사례

~~스트림 처리 과정에서 중복이 발생하더라도 출력 스트림에서 걸러 내는 것은 상당히 단순하다~~

~~스트림 처리 애플리케이션이 다수의 레코드를 집적해서 하나로 만들 경우, 결과 레코드가 잘못되었는지의 여부를 판단하는 것은 훨씬 더 어렵다 몇 개의 입력 레코드가 한 번 이상 처리되었을 수 있기 때문이다. 주어진 입력을 다시 처리하지 않는 한 결과를 교정하는 것은 불가능하다.~~

### 8.2.2 트랜잭션이 해결하는 문제

1. 애플리케이션 크래시로 인한 재처리
하나는 결과를 출력 토픽에 쓰는 것이고 또 하나는 우리가 읽어 온 메시지의 오프셋을 커밋함
마지막으로 커밋된 오프셋에서부터 크래시가 난 시점까지, 애플리케이션에 의해 처리된 모든 레코드들은 다시 처리될 것이며 결과 역시 출력 토픽에 다시 쓰여지며 중복이 발생함
2. 좀비 애플리케이션에 의해 발생하는 재처리
멈췄던 애플리케이션의 첫 번째 인스턴스가 다시 작동할 경우 마지막으로 읽어왔던 레코드 배치를 처리하고 결과를 출력 토픽에 씀
레코드를 읽어오기 위해 새로 카프카를 폴링하거나, 하트비트를 보냈다가 자기가 죽은 것으로 판정되어 다른 인스턴스들이 현재 해당 파티션들을 할당받은 상태라는 걸 알아차릴 때까지 이 작업을 계속 함 

### 8.2.3 트랜잭션은 어떻게 ‘정확히 한 번’을 보장하는가?

**카프카 트랜잭션의 원자적 다수 파티션 쓰기 기능 도입**

1. 토픽에서 데이터를 읽어서, 처리하고, 결과를 다른 토피에 쓴다.
2. ‘정확히 한 번’ 처리라 함은 이러한 읽기, 처리, 쓰기 작업이 원자적으로 이루어짐
3. 읽어 온 원본 메시지의 오프셋이 커밋되고 결과가 성공적으로 쓰여지거나, 아니면 둘 다 안 일어나거나, 우리는 부분적인 결과(오프셋은 커밋되었는데 결과는 안 쓰여진다던가, 그반대)가 결코 발생하지 않을 거라는 보장이 필요
4. 카프카 트랜잭션은 원자적 다수 파티션 쓰기 기능 도입

오프셋을 커밋하는 것과 결과를 쓰는 것은 둘 다 파티션에 메시지를 쓰는 과정을 수반한다는 점에서 착안

오프셋은 _*consumer*_*offsets* 토픽에 쓰여진다는 점이 다를뿐임

우리가 트랜잭션을 시작해서 양쪽에 메시지를 쓰고 둘 다 성공해서 커밋할 수 있다면(아니면 재시도하기 위해 중단할 수 있다면), 그 다음부터 그 다음부터는 ‘정확히 한 번’ 의미 구조가 알아서 해 준다.

→ 트랜잭션적 프로듀서 사용 : 원자적 다수 파티션 쓰기 사용

1. transactional.id : 설정으로 재시작하더라도 값을 유지로 동일한 프로듀서로 식별
2. initTransactions() 호출로 초기화 

좀비 인스턴스가 중복 프로듀서를 생성하는 것을 방지하려면 좀비 펜싱 혹은 애플리케이션의 좀비 인스턴스가 출력 스트림에 결과를 쓰는 것을 방지할 필요가 있음

가장 일반적인 좀비 펜싱 방벙인 에포크를 사용하는 방식이 쓰임

트랜잭션 대부분은 프로듀서 기능임

1. 트랜잭션 프로듀서를 생성
2. 트랜잭션을 시작
3. 다수의 파티션에 레코드를 씀
4. 이미 처리된 레코드들을 표시하기 위해 오프셋을 씀
5. 트랜잭션을 커밋하거나 중단하는 작업을 프로듀서에서 함

→ 컨슈머에 올바른 격리 수준이 설정되어 있지 않을 경우, 우리가 기대하는 ‘정확히 한 번’ 보장은 이루어지지 않음

isolation.level 설정 값을 잡아주면서 쓰여진 메시지들을 읽어오는 방식 제어 함

read_committed로 잡혀 있을 경우

→ 토픽들을 구독한 뒤 consumer.poll()을 호출하면 커밋된 트랜잭션에 속한 메시지나 처음부터 트랜잭션에 속하지 않는 메시지만 리턴된다(중단 된 트랜잭션에 속한 메시지나 아직 진행중인 트랜잭션에 속하는 메시지는 리턴되지 않음)

isolation.level 기본값 : read_uncommitted

transsaction.timeout.ms : 15분

### 8.2.4 트랜잭션으로 해결할 수 없는 문제들

- 트랜잭션은 아예 작동하지 않던가 아니면 원하는 보장을 달성하기 위해 추가적인 노력이 필요

트랜잭션 기능 관련에서 자주하는 두 가지 실수

1. ‘정확히 한번 보장’이 카프카에 대한 쓰기 이외의 작동에서도 보장된다고 착각
2. 컨슈머가 항상 전체 트랜잭션을 읽어 언도가 가정

‘정확히 한 번’ 보장에 도움이 되지 않는 몇 가지 경우

1. 스트림 처리에 있어서의 부수 효과(side effect)
카프카에 쓰여지는 레코드에만 적용되며 레코드 중복 방지로 시퀀스 넘버를 사용하거나 트랜잭션 중단 혹은 취소하기 마커를 사용하는 것은 카프카 안에서만 작동함 
이메일 발송을 취소시킬 수 있는 것은 아님
2. 카프카 토픽에서 읽어서 데이터베이스에 쓰는 경우
카프카가 아닌 외부 데이터베이스에 결과물을 쓴다.
프로듀서가 사용되지 않고 레코드는 JDBC와 같은 드라이버로 데이터베이스에 쓰고
오프셋은 컨슈머에 의해 카프카에 커밋됨
하나의 트랜잭션에서 외부 데이터베이스에는 결과를 쓰고 카프카에는 오프셋을 커밋할 수 있도록 해주는 메커니즘 같은건 없음

@ MSA에서는 하나의 원자적 트랜잭션 안에서 데이터베이스도 업데이트하고 카프카에 메시지도 써야 하는 경우가 종종 있음(둘 다 성공하든, 둘다 안되든) 이러한 일반적인 문제에 대한 일반적인 해법은 **아웃박스패턴** 이라 불림

카프카 토픽에 메시지를 쓰는 작업까지만 하고 별도의 메시지 중계 서비스가 카프카로부터 메시지를 읽어와서 데이터베이스를 업데이트함

→ 데이터베이스 테이블을 아웃박스로 사용하고 릴레이 서비스가 테이블 업데이트 내역을 카프카에 메시지로 쓰는 것임

1. 데이터베이스에서 읽어서, 카프카에 쓰고, 여기서 다시 다른 데이터베이스에 쓰는 경우

하나의 앱에서 데이터베이스 데이터를 읽고, 트랜잭션을 구분하고, 카프카에 레코드를 쓰고, 여기서 다시 다른 데이터베이스에 레코드를 쓰고, 그와중에도 우너본 데이터베이스의 원래 트랜잭션을 관리할 수 있는 앱을 개발할 수 있으면 좋음
불행히도 카프카 트랜잭션은 이러한 종류의 종단 보장에 필요한 기능을 가지고 있지 않음

하나의 트랜잭션 안에서 레코드와 오프셋을 함께 커밋하는 문제 외에도 또 다른 문제가 있음

카프카 컨슈머의 read_committed 보장은 데이터베이스 트랜잭션을 보존하기엔 너무 약함

일부 토픽에서 랙이 발생했을 수도 있는 만큼 이미 커밋된 트랜잭션의 레코드를 모두 봤을거라는 보장이 없음

1. 한 클러스터에서 다른 클러스터로 데이터 복제

하나의 카프카 클러스터에서 다른 클러스터로 데이터를 복사할 때 ‘정확히 한 번’을 보장할 수 있음

쓰는 시점에서 이 제안은 여전히 계류중이지만, 알고리즘 자체는 명확하게 설명되어 있음

이 제안은 원본 클러스터의 각 레코드가 대상 클러스터에 정확히 한 번 복사될 것을 보장

트랜잭션의 원자성을 보장하지 않음

애플리케이션이 여러 개의 레코드와 오프셋을 트랜잭션적으로 쓰고, 미러 메이커 2.0이 레코드들을 다른 카프카 클러스터에 복사한다면, 복사 과정에서 트랜잭션 송석이나 보장은 유실됨

카프카에서 데이터를 읽어오는 컨슈머 입장에서는 트랜잭션의 모든 데이터를 읽어왔는지 알 수 없고 보장할 수도 없음

1. 발행/구독 패턴

read_committed 모드가 설정 된 컨슈머들은 중단된 트랜잭션에 속한 레코드들을 보지 못하지만 ‘정확히 한 번’에 미치지 못함 오프셋 커밋 로직에 따라 컨슈머들은 메시지를 한 번 이상 처리할 수 있음

이 경우 카프카가 보장하는 것은 JMS 트랜잭션에서 보장하는 것과 비슷

커밋되지 않은 트랜잭션들이 보이지 않도록 컨슈머들에 read_committed 설정이 되어 있어야 한다는 전제 조건이 붙음 JMS 브로커들은 모든 컨슈머에게 커밋되지 않은 트랜잭션의 레코드를 주지 않는다

@ 메시지를 쓰고 나서 커밋하기 전에 다른 애플리케이션이 응답하기를 기다리는 패턴은 반드시 피해야함

다른 애플리케이션은 트랜잭션이 커밋될 떄까지 메시지를 받지 못할것이기에 결과적으로 데드락이 발생함

### 8.2.5 트랜잭션 사용법

processing.guarantee = exactly_once or exactly_once_beta 

### 8.2.6 트랜잭션 ID와 펜싱

펜싱을 보장하는 유일한 방법은 트랜잭션 ID를 파티션에 정적으로 대응시켜 보는것뿐이었음

→ 각 파티션이 항상 단 하나의 트랜잭션 ID에 의해 읽혀짐을 보장할 수 있음

→ 만약 트랜잭션 ID가 A인 프로듀서가 토픽 T에 메시지를 쓰다가 연결이 끊어지고, 트랜잭션 ID가 B인 새 프로듀서가 대신 들어올 경우, 연결이 복구된 A쪽 프로듀서는 좀비지만 새 프로듀서와 트랜잭션 ID가 다르기 때문에 펜싱 되지도 않음

→ 스레드에 할당되는 트랜잭션 ID는 랜덤하게 결정되고 동일한 파티션에 쓰기 작업을 할 떄 동일한 트랜잭션 ID가 쓰일거라는 보장이 없음

펜싱을 수행하는 두번째 방법 

→ 트랜잭션 ID와 컨슈머 그룹 메타 데이터를 함꼐 사용하는 펜싱을 도입

프로듀서의 오프셋 커밋 메서드를 호출할 때 단순한 컨슈머 그룹 ID가 아닌, 컨슈머 그룹 메타데이터를 인수로 전달함

### 8.2.7 트랜잭션의 작동 원리

카프카 트랜잭션 기능의 기본적인 알고리즘 : 칸디-램포트 스냅샷 알고리즘의 영향을 받음

- 통신 채널을 통해 마커라 불리는 컨트롤 메시지를 보내고, 이 마커의 도착을 기준으로 일관적인 상태를 결정
- 카프카의 트랜잭션은 다수의 파티션에 대해 트랜잭션이 커밋되었거나 중단되었다는 것을 표시하기 위해 마커 메시지 사용
- 프로듀서가 트랜잭션을 커밋하기 위해 트랜잭션 코디네이터에 ‘커밋’ 메시지를 보내면 트랜잭션 코디네이터가 트랜잭션에 관련된 모든 파티션에 커밋 마커를 쓴다.
- 하지만 일부 파티션에만 커밋 메시지가 쓰여진 상태에서 프로듀서가 크래시 나면 어떻게 될까
    
    → 카프카 트랜잭션은 2단계 커밋과 트랜잭션 로그를 이용해 문제를 해결함
    
    1. 현재 진행중인 트랜잭션이 존재함을 로그에 기록하며 연관된 파티션들 역시 함께 기록
    2. 로그에 커밋 혹은 중단 시도를 기록(일단 로그에 기록이 남으면 최종적으로는 커밋되거나 중단되어야 함)
    3. 모든 파티션에 트랜잭션 마커를 씀
    4. 트랜잭션이 종료되었을을 로그로 씀

알고리즘 구현을 위해서는 트랜잭션 로그가 필요하며 transaction_state라는 이름의 내부 토픽을 사용함

1. initTrasaction() 호출하여 트랜잭션 프로듀서 등록
2. beginTrasaction() 호출하여 프로듀서에 현재 진행중인 트랜잭션이 있음을 알려줌
3. 쓰기 작업 완료 후 커밋 할 준비가 되면 레코드들의 오프셋부터 커밋sendOffsetsToTransaction() 호출
4. 커밋 아니면 중단을 해줄 경우 : commitTransaction()이나 abortTransaction() 호출
    1. 트랜잭션 코디네이터에 EndTxn 요청 전송
    2. 트랜잭션 코디네이터는 트랜잭션 로그에 커밋 혹은 중단 시도를 기록함

## 8.3 트랜잭션 성능

프로듀서

- 트랜잭션은 프로듀서에 약간의 오버헤드 발생
- 트랜잭션 ID 등록 요청은 단 한번 발생
- 파티션 별로 최대 한번씩만 이루어짐
- 각 트랜잭션이 커밋 요청을 전송하면, 파티션마다 커밋 마커를 추가
- 트랜잭션 초기회와 커밋 요청은 동기적으로 작동하므로 성공적으로 완료하거나 실패하거나 타임아웃이 발생
- 프로듀서에 있어서 트랜잭션 오버헤드는 포함된 메시지 수와는 무관
- 메시지를 집어 넣는 쪽이 상대적으로 오버헤드가 적을뿐 아니라 동기적으로 실행되는 단계의 수도 줄어들어 전체 처리량이 올라감

컨슈머

- 커밋 마커를 읽어오는 작업에서 약간의 오버헤드 발생
- 트랜잭선 기능이 컨슈머 성능에 미치는 핵심적인 영향은 read_committed 모드 컨슈머에서는 아직 완료되지 않은 트랜잭션의 레코드들이 리턴되지 않음
- 트랜잭션 커밋 사이의 간격이 길어질수록 컨슈머는 메시지가 리턴될 떄까지 더 오랫동안 기다려야 함
- 결과적으로 종단 지연 역시 그만큼 길어짐
- 아직 완료되지 않은 트랜잭션에 속하는 메시지들을 버퍼링할 필요가 없음
- 브로커는 컨슈머가 보낸 읽기 요청을 받는다고 해서 이 메시지를 리턴하지 않음
- 트랜잭션 데이터를 읽을 때 컨슈머 쪽에 추가 작업이 없어서 자연히 처리량이 줄어들지도 않음

## 8.4 요약

‘정확히 한 번’의미 구조는 이해하기는 어렵지만, 쓰기는 쉽다

간단한 설정으로 두 가지 방법을 사용 가능함
