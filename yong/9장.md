# 9장 데이터 파이프라인 구축하기

데이터 파이프라인에 있어서 카프카가 갖는 주요한 역할은 데이터 파이프라인의 다양한 단계 사이사이에 매우 크고 안정적인 버퍼 역할을 해줄 수 있다는 점

데이터 파이프 라인의 데이터 쓰는 쪽과 읽는 쪽을 분리함으로써 하나의 원본에서 가져온 동일한 데이터를 서로 다른 적시성과 가용성 요구 조건을 가진 여러 대상 애플리케이션이나 시스템으로 보낼 수 있게 함 

## 9.1 데이터 파이프라인 구축 시 고려 사항

### 9.1.1 적시성

데이터 파이프라인은 두 가지 형태로 됨

- 하루에 한번 대량의 데이터를 받는 시스템
- 데이터가 생성된 뒤 몇 밀리초 안에 받아야 하는 시스템

이러한 맥락에서 카프카를 이해하는 좋은 방법

→ 쓰는 쪽과 읽는 쪽 사이의 시간적 민감도에 대한 요구 조건을 분리시키는 거대한 버퍼

### 9.1.2 신뢰성

단일 장애점을 최대한 피하는 한편 모든 종류의 장애 발생에 대해 신속하고 자동화된 복구를 수행해야 함

데이터 파이프라인은 많은 경우 중요한 비즈니스 시스템에 데이터가 전달되는 통로이므로, 몇 초간의 장애가 발생하는 것만으로 전체 시스템에 큰 지장을 줌

데이터 유실을 허용하는 시스템도 있지만, 대부분의 경우 최소 한번 보장을 요구하는게 보통이기에 원본 시스템에서 발생한 이벤트가 모두 목적지에 도착해야 함

‘정확히 한번’ 전달 보장을 요구하는 경우도 볼 수 있음

→ 원본 시스템에서 발생한 모든 이벤트가 유실도, 중복도 없이 목적지에 도착해야 함 

‘최소 한번’ 전달을 보장하며, 트랜잭션 모델이나 고유 키를 지원하는 외부 데이터 저장소와 결합 됐을 때 ‘정확히 한번’까지도 보장 가능

### 9.1.3 높으면서도 조정 가능한 처리율

처리율이 증가해야 하는 경우에도 적응할 수 있어야 함 

카프카가 쓰는 쪽과 읽는 쪽 사이에서 버퍼 역할을 하므로 프로듀서의 처리율과 컨수머의 처리율을 묶어서 생각하지 않아도 됨 

### 9.1.4 데이터 형식

다양한 데이터 형식을 지원하므로 카프카에 사용하는 데이터 형식이 무엇이든 사용할 수 있는 커넥터는 영향을 받지 않음

카프카의 데이터를 외부 시스템에 쓸 경우, 싱크 커넥터가 외부 시스템에 쓰여지는 데이터의 형식을 책임짐

### 9.1.5 변환

ETL과 ELT 두 가지 방식을 지원함

### 9.1.6 보안

고려 해야 할 점

1. 누가 카프카로 수집되는 데이터에 접근할 수 있는가?
2. 파이프라인을 통과하는 데이터가 암호화되었다고 확신할 수 있는가? 이것은 여러 데이터센터에 걸쳐 구축된 데이터 파이프라인의 경우 특히 중요함
3. 누가 파이프라인을 변경할 수 있는가?
4. 만약 파이프라인이 접근이 제한된 곳의 데이터를 읽거나 써야 할 경우, 문제없이 인증을 통과할 수 있는가?
5. 개인 식별 정보PII를 저장하고, 접근하고, 사용할 때 법과 규제를 준수하는가?

### 9.1.7 장애 처리

고려 사항

1. 잘못된 레코드가 파이프라인으로 유입되는 것을 방지할 수 있을까?
2. 파싱할 수 없는 레코드가 주여졌을 때 복구가 가능할까?
3. 결함이 있는 레코드를 바로 잡아 재처리할 수 있을까?
4. 잘못된 이벤트가 문제없는 것처럼 보여서 며칠이 지난 뒤에야 문제가 있다는걸 알아차렸다면 어떻게 해야할까?

### 9.1.8 결합과 민첩성

데이터 원본과 대상을 분리하는게 중요하며 의도치 않게 결합이 생기는 경우는 아래오 같음

1. 임기응변 파이프라인
    - 데이터 파이프라인이 특정한 엔드포인트에 강하게 결합되면 설치, 유지보수, 모니터링에 상당한 노력이 필요함
2. 메타데이터 유실
    - 데이터 파이프라인이 스키마 메타데이터를 보존하지 않고 스키마 진화 역시 지원하지 않는다면, 소스쪽에서 데이터를 생성하는 소프트웨어와 싱크 쪽에서 데이터를 사용하는 소프트웨어를 강하게 결합시키게 됨
    - 만약 파이프라인이 스키마 진화를 지원한다면, 각 팀은 시스템 중단을 걱정할 필요 없이 자신들의 어플리케이션을 변경할 수 있음
3. 과도한 처리
    - 데이터 파이프라인에서도 어느정도의 데이터 처리는 피할 수 없음
    - 너무 많은 처리를 하면 하단에 있는 시스템들이 데이터 파이프라인을 구축할 때 어떤 필드를 보존할지, 어떻게 집적할지, 등에 선택지가 별로 남지 않게 됨
    - 데이터를 처리하고 집적하는 방법은 어플리케이션이 알아서 결정하게 하는 것이 좀 더 유연한 방법임

## 9.2 카프카 커넥트 vs 프로듀서/컨슈머

카프카 커넥트와 프로듀서/컨슈머를 언제 무엇을 써야 할지 고민일 때

카프카 클라이언트 : 어플리케이션의 코드를 변경할 수 있으면서 카프카에 데이터를 쓰거나 읽어오고 싶을 때 씀

카프카 커넥트 : 직접 코드나 API를 작성하지 않고 변경할 수 없는 데이터 저장소에 연결시켜야 할 떄 씀

## 9.3 카프카 커넥트

카프카 커넥트는 아파치의 일부이며 다른 데이터 저장소 사이에 확장성과 신뢰성을 가지며 데이터를 주고 받을 수 있는 수단을 제공함

커넥트는 커넥트 플러그인을 개발하고 실행하기 위한 API와 런타임을 제공함

→ 카프카 커넥트가 실행시키는 라이브러리로, 데이터를 이동시키는 것을 담당

1. 여러 워커 프로세스들의 클러스터 형태로 실행됨
2. 대용량의 데이터 이동을 병렬화해서 처리하고 워커의 유휴 자원을 더 효율적으로 활용하기 위해 태스크를 추가로 실행시킴
3. 싱크 커넥트 태스크는 워커로부터 커넥트 자료 객체를 받아서 대상 시스템에 쓰는 작업을 담당
4. 카프카 커넥트는 자료 객체를 카프카에 쓸 때 사용되는 형식으로 바꿀 수 있도록 컨버터를 사용함
5. JSON 형식을 지원하며, 다양한 형식으로 바꿀 수 있도록 컨버터를 지원

@ 변경 데이터 캡처와 디비지움 프로젝트

DB의 새로 들어온 레코드를 찾아내고 트랜잭션 로그를 직접 읽어갈 수 있도록 하고 읽음으로써 내용물의 변경을 탐지하는 방식을 변경 데이터 캡처라(CDC)라고 함 

대부분의 ETL 시스템들은 CDC를 데이터 저장소로 사용함 

디비지움 프로젝트 : 다양한 데이터베이스에 대한 고품질의 오픈소스 CDC 커넥터를 제공함

카프카로의 데이터 스트리밍을 생각중이라면, 우리는 디비지움에 포함된 CDC 커넥터를 사용할 것을 강력히 권장함

커넥터에 대한 문서화를 제공하는 것을 넘어서 CDC에 관련된 디자인 패턴이나 활용 사례에 대해서도 다루고 있음

### 9.3.5 카프카 커넥트 : 좀더 자세히 알아보기

1. 커넥터와 태스크
    - 커넥터
        1. 커넥터에서 몇 개의 태스크가 실행되어야 하는지 결정
        2. 데이터 복사 작업을 각 태스크에 어떻게 분장해 줄지 결정
        3. 워커로부터 태스크 설정을 얻어와서 태스크에 전달
    - 태스크
        1. 데이터를 실제로 카프카에 넣거나 가져오는 작업을 담당
        2. 모든 태스크는 워커로부터 컨텍스트를 받아서 초기화 함
        3. 싱크 태스크는 워커를 통해 카프카 레코드를 받아서 외부 시스템에 쓰는 작업을 담당
2. 워커 
    - 카프카 커넥트의 워커 프로세스는 커넥터와 태스크를 실행시키는 역할을 맡는 ‘컨테이너’ 프로세스라고 할 수 있음
    - 커넥터와 설정을 정의 하는 http 요청을 처리
    - 커넉터 설정을 내부 카프카 토픽에 저장하고 커넥터와 태스크 실행하며 적절한 설정값 전달 역할
3. 컨버터 및 커넉트 데이터 모델
    - 카프카 커넥터 API에는 데이터 API가 포함되어 있는데, 이 API는 데이터 객체와 객체의 구조를 나타내는 스키마 모두를 다룸
    - 사용 가능한 컨버터만 있다면, 어떤 커넥터도 레코드 형식에 상관없이 사용할 수 있음
4. 오프셋 관리
    - 워커 프로세스가 커넥터에 제공하는 편리한 기능 중 하나

## 9.4 카프카 커넥트의 대안

### 9.4.1 다른 데이터 저장소를 위한 수집 프레임워크

카프카가 아키텍처의 핵심부분이면서 많은 수의 소스와 싱크를 연결하는 것이 목표라면 카프카 커넥트 API를 추천

실제로 구축중인 것이 하둡 중심 혹은 엘라스틱서치 중심 시스템이고 카프카는 그저 수많은 입력 중 하나일뿐이라면 플룸이나 로그스태시를 쓰는것이 더 바람직함

### 9.4.2 GUI 기반 ETL 툴

탈렌드, 펜타호, 아파치 나이파이, 스트림세츠와 같은 대안들을 카프카와 데이터 교환을 지원함

### 9.4.3 스트림 프로세싱 프레임워크

카프카에서 이벤트를 읽어와서 다른 시스템에 쓰는 기능을 포함함

현재 사용중인 스트림 처리 프레임워크가 해당 시스템에 대한 쓰기를 지우너하고 또 카프카에서 읽어 온 이벤트를 처리하는 데 해당 프레임워크를 쓰고자 한다면 데이터 통합에도 동일한 프레임워크가 합리적임
